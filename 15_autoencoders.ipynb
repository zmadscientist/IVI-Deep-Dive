{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "**Chapter 15 \u2013 Autoencoders**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "_This notebook contains all the sample code and solutions to the exercises in chapter 15._", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Setup", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "%%bash\npwd\nls tmp/", 
            "cell_type": "code", 
            "execution_count": 8, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "/gpfs/fs01/user/s37a-6a8375ad9b78b5-6459f7095f24/notebook/work\ndata\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# To support both python 2 and python 3\nfrom __future__ import division, print_function, unicode_literals\n\n# Common imports\nimport numpy as np\nimport os\nimport sys\n\n# to make this notebook's output stable across runs\ndef reset_graph(seed=42):\n    tf.reset_default_graph()\n    tf.set_random_seed(seed)\n    np.random.seed(seed)\n\n# To plot pretty figures\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nplt.rcParams['axes.labelsize'] = 14\nplt.rcParams['xtick.labelsize'] = 12\nplt.rcParams['ytick.labelsize'] = 12\n\n# Where to save the figures\nPROJECT_ROOT_DIR = \".\"\nCHAPTER_ID = \"autoencoders\"\n\ndef save_fig(fig_id, tight_layout=True):\n    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n    print(\"Saving figure\", fig_id)\n    if tight_layout:\n        plt.tight_layout()\n    plt.savefig(path, format='png', dpi=300)", 
            "cell_type": "code", 
            "execution_count": 1, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "A couple utility functions to plot grayscale 28x28 image:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "def plot_image(image, shape=[28, 28]):\n    plt.imshow(image.reshape(shape), cmap=\"Greys\", interpolation=\"nearest\")\n    plt.axis(\"off\")", 
            "cell_type": "code", 
            "execution_count": 2, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "def plot_multiple_images(images, n_rows, n_cols, pad=2):\n    images = images - images.min()  # make the minimum == 0, so the padding looks white\n    w,h = images.shape[1:]\n    image = np.zeros(((w+pad)*n_rows+pad, (h+pad)*n_cols+pad))\n    for y in range(n_rows):\n        for x in range(n_cols):\n            image[(y*(h+pad)+pad):(y*(h+pad)+pad+h),(x*(w+pad)+pad):(x*(w+pad)+pad+w)] = images[y*n_cols+x]\n    plt.imshow(image, cmap=\"Greys\", interpolation=\"nearest\")\n    plt.axis(\"off\")", 
            "cell_type": "code", 
            "execution_count": 3, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# PCA with a linear Autoencoder", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Build 3D dataset:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import numpy.random as rnd\n\nrnd.seed(4)\nm = 200\nw1, w2 = 0.1, 0.3\nnoise = 0.1\n\nangles = rnd.rand(m) * 3 * np.pi / 2 - 0.5\ndata = np.empty((m, 3))\ndata[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * rnd.randn(m) / 2\ndata[:, 1] = np.sin(angles) * 0.7 + noise * rnd.randn(m) / 2\ndata[:, 2] = data[:, 0] * w1 + data[:, 1] * w2 + noise * rnd.randn(m)", 
            "cell_type": "code", 
            "execution_count": 5, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "Normalize the data:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(data[:100])\nX_test = scaler.transform(data[100:])", 
            "cell_type": "code", 
            "execution_count": 6, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "Now let's build the Autoencoder...", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Note: instead of using the `fully_connected()` function from the `tensorflow.contrib.layers` module (as in the book), we now use the `dense()` function from the `tf.layers` module, which did not exist when this chapter was written. This is preferable because anything in contrib may change or be deleted without notice, while `tf.layers` is part of the official API. As you will see, the code is mostly the same.\n\nThe main differences relevant to this chapter are:\n* the `scope` parameter was renamed to `name`, and the `_fn` suffix was removed in all the parameters that had it (for example the `activation_fn` parameter was renamed to `activation`).\n* the `weights` parameter was renamed to `kernel` and the weights variable is now named `\"kernel\"` rather than `\"weights\"`,\n* the bias variable is now named `\"bias\"` rather than `\"biases\"`,\n* the default activation is `None` instead of `tf.nn.relu`", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import tensorflow as tf\n\nreset_graph()\n\nn_inputs = 3\nn_hidden = 2  # codings\nn_outputs = n_inputs\n\nlearning_rate = 0.01\n\nX = tf.placeholder(tf.float32, shape=[None, n_inputs])\nhidden = tf.layers.dense(X, n_hidden)\noutputs = tf.layers.dense(hidden, n_outputs)\n\nreconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n\noptimizer = tf.train.AdamOptimizer(learning_rate)\ntraining_op = optimizer.minimize(reconstruction_loss)\n\ninit = tf.global_variables_initializer()", 
            "cell_type": "code", 
            "execution_count": 7, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "n_iterations = 1000\ncodings = hidden\n\nwith tf.Session() as sess:\n    init.run()\n    for iteration in range(n_iterations):\n        training_op.run(feed_dict={X: X_train})\n    codings_val = codings.eval(feed_dict={X: X_test})", 
            "cell_type": "code", 
            "execution_count": 8, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "fig = plt.figure(figsize=(4,3))\nplt.plot(codings_val[:,0], codings_val[:, 1], \"b.\")\nplt.xlabel(\"$z_1$\", fontsize=18)\nplt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n#save_fig(\"linear_autoencoder_pca_plot\")\nplt.show()", 
            "cell_type": "code", 
            "execution_count": 9, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7f6958585b10>"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# Stacked Autoencoders", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Let's use MNIST:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"tmp/data/\")", 
            "cell_type": "code", 
            "execution_count": 10, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Extracting tmp/data/train-images-idx3-ubyte.gz\nExtracting tmp/data/train-labels-idx1-ubyte.gz\nExtracting tmp/data/t10k-images-idx3-ubyte.gz\nExtracting tmp/data/t10k-labels-idx1-ubyte.gz\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "## Train all layers at once", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Let's build a stacked Autoencoder with 3 hidden layers and 1 output layer (ie. 2 stacked Autoencoders). We will use ELU activation, He initialization and L2 regularization.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Note: since the `tf.layers.dense()` function is incompatible with `tf.contrib.layers.arg_scope()` (which is used in the book), we now use python's `functools.partial()` function instead. It makes it easy to create a `my_dense_layer()` function that just calls `tf.layers.dense()` with the desired parameters automatically set (unless they are overridden when calling `my_dense_layer()`).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "reset_graph()\n\nfrom functools import partial\n\nn_inputs = 28 * 28\nn_hidden1 = 300\nn_hidden2 = 150  # codings\nn_hidden3 = n_hidden1\nn_outputs = n_inputs\n\nlearning_rate = 0.01\nl2_reg = 0.0001\n\nX = tf.placeholder(tf.float32, shape=[None, n_inputs])\n\nhe_init = tf.contrib.layers.variance_scaling_initializer() # He initialization\n#Equivalent to:\n#he_init = lambda shape, dtype=tf.float32: tf.truncated_normal(shape, 0., stddev=np.sqrt(2/shape[0]))\nl2_regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\nmy_dense_layer = partial(tf.layers.dense,\n                         activation=tf.nn.elu,\n                         kernel_initializer=he_init,\n                         kernel_regularizer=l2_regularizer)\n\nhidden1 = my_dense_layer(X, n_hidden1)\nhidden2 = my_dense_layer(hidden1, n_hidden2)\nhidden3 = my_dense_layer(hidden2, n_hidden3)\noutputs = my_dense_layer(hidden3, n_outputs, activation=None)\n\nreconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n\nreg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\nloss = tf.add_n([reconstruction_loss] + reg_losses)\n\noptimizer = tf.train.AdamOptimizer(learning_rate)\ntraining_op = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\nsaver = tf.train.Saver() # not shown in the book", 
            "cell_type": "code", 
            "execution_count": 10, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "Now let's train it! Note that we don't feed target values (`y_batch` is not used). This is unsupervised training.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "n_epochs = 5\nbatch_size = 150\n\nwith tf.Session() as sess:\n    init.run()\n    for epoch in range(n_epochs):\n        n_batches = mnist.train.num_examples // batch_size\n        for iteration in range(n_batches):\n            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\") # not shown in the book\n            sys.stdout.flush()                                          # not shown\n            X_batch, y_batch = mnist.train.next_batch(batch_size)\n            sess.run(training_op, feed_dict={X: X_batch})\n        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})   # not shown\n        print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)           # not shown\n        saver.save(sess, \"./my_model_all_layers.ckpt\")                  # not shown", 
            "cell_type": "code", 
            "execution_count": 11, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 Train MSE: 0.0203432\n1 Train MSE: 0.011473\n2 Train MSE: 0.010229\n3 Train MSE: 0.00990439\n4 Train MSE: 0.0103764\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "This function loads the model, evaluates it on the test set (it measures the reconstruction error), then it displays the original image and its reconstruction:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "def show_reconstructed_digits(X, outputs, model_path = None, n_test_digits = 2):\n    with tf.Session() as sess:\n        if model_path:\n            saver.restore(sess, model_path)\n        X_test = mnist.test.images[:n_test_digits]\n        outputs_val = outputs.eval(feed_dict={X: X_test})\n\n    fig = plt.figure(figsize=(8, 3 * n_test_digits))\n    for digit_index in range(n_test_digits):\n        plt.subplot(n_test_digits, 2, digit_index * 2 + 1)\n        plot_image(X_test[digit_index])\n        plt.subplot(n_test_digits, 2, digit_index * 2 + 2)\n        plot_image(outputs_val[digit_index])", 
            "cell_type": "code", 
            "execution_count": 12, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "show_reconstructed_digits(X, outputs, \"./my_model_all_layers.ckpt\")\n#save_fig(\"reconstruction_plot\")", 
            "cell_type": "code", 
            "execution_count": 13, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "INFO:tensorflow:Restoring parameters from ./my_model_all_layers.ckpt\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7fe188326ed0>"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "## Tying weights", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "It is common to tie the weights of the encoder and the decoder (`weights_decoder = tf.transpose(weights_encoder)`). Unfortunately this makes it impossible (or very tricky) to use the `tf.layers.dense()` function, so we need to build the Autoencoder manually:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "reset_graph()\n\nn_inputs = 28 * 28\nn_hidden1 = 300\nn_hidden2 = 150  # codings\nn_hidden3 = n_hidden1\nn_outputs = n_inputs\n\nlearning_rate = 0.01\nl2_reg = 0.0005", 
            "cell_type": "code", 
            "execution_count": 14, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "activation = tf.nn.elu\nregularizer = tf.contrib.layers.l2_regularizer(l2_reg)\ninitializer = tf.contrib.layers.variance_scaling_initializer()\n\nX = tf.placeholder(tf.float32, shape=[None, n_inputs])\n\nweights1_init = initializer([n_inputs, n_hidden1])\nweights2_init = initializer([n_hidden1, n_hidden2])\n\nweights1 = tf.Variable(weights1_init, dtype=tf.float32, name=\"weights1\")\nweights2 = tf.Variable(weights2_init, dtype=tf.float32, name=\"weights2\")\nweights3 = tf.transpose(weights2, name=\"weights3\")  # tied weights\nweights4 = tf.transpose(weights1, name=\"weights4\")  # tied weights\n\nbiases1 = tf.Variable(tf.zeros(n_hidden1), name=\"biases1\")\nbiases2 = tf.Variable(tf.zeros(n_hidden2), name=\"biases2\")\nbiases3 = tf.Variable(tf.zeros(n_hidden3), name=\"biases3\")\nbiases4 = tf.Variable(tf.zeros(n_outputs), name=\"biases4\")\n\nhidden1 = activation(tf.matmul(X, weights1) + biases1)\nhidden2 = activation(tf.matmul(hidden1, weights2) + biases2)\nhidden3 = activation(tf.matmul(hidden2, weights3) + biases3)\noutputs = tf.matmul(hidden3, weights4) + biases4\n\nreconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\nreg_loss = regularizer(weights1) + regularizer(weights2)\nloss = reconstruction_loss + reg_loss\n\noptimizer = tf.train.AdamOptimizer(learning_rate)\ntraining_op = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()", 
            "cell_type": "code", 
            "execution_count": 15, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "saver = tf.train.Saver()", 
            "cell_type": "code", 
            "execution_count": 16, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "n_epochs = 5\nbatch_size = 150\n\nwith tf.Session() as sess:\n    init.run()\n    for epoch in range(n_epochs):\n        n_batches = mnist.train.num_examples // batch_size\n        for iteration in range(n_batches):\n            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n            sys.stdout.flush()\n            X_batch, y_batch = mnist.train.next_batch(batch_size)\n            sess.run(training_op, feed_dict={X: X_batch})\n        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n        print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)\n        saver.save(sess, \"./my_model_tying_weights.ckpt\")", 
            "cell_type": "code", 
            "execution_count": 17, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 Train MSE: 0.0150667\n1 Train MSE: 0.0164884\n2 Train MSE: 0.0173757\n3 Train MSE: 0.0168781\n4 Train MSE: 0.0155875\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "show_reconstructed_digits(X, outputs, \"./my_model_tying_weights.ckpt\")", 
            "cell_type": "code", 
            "execution_count": 18, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "INFO:tensorflow:Restoring parameters from ./my_model_tying_weights.ckpt\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7fe3046f96d0>"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "## Training one Autoencoder at a time in multiple graphs", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "There are many ways to train one Autoencoder at a time. The first approach is to train each Autoencoder using a different graph, then we create the Stacked Autoencoder by simply initializing it with the weights and biases copied from these Autoencoders.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Let's create a function that will train one autoencoder and return the transformed training set (i.e., the output of the hidden layer) and the model parameters.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "reset_graph()\n\nfrom functools import partial\n\ndef train_autoencoder(X_train, n_neurons, n_epochs, batch_size,\n                      learning_rate = 0.01, l2_reg = 0.0005, seed=42,\n                      hidden_activation=tf.nn.elu,\n                      output_activation=tf.nn.elu):\n    graph = tf.Graph()\n    with graph.as_default():\n        tf.set_random_seed(seed)\n\n        n_inputs = X_train.shape[1]\n\n        X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n        \n        my_dense_layer = partial(\n            tf.layers.dense,\n            kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),\n            kernel_regularizer=tf.contrib.layers.l2_regularizer(l2_reg))\n\n        hidden = my_dense_layer(X, n_neurons, activation=hidden_activation, name=\"hidden\")\n        outputs = my_dense_layer(hidden, n_inputs, activation=output_activation, name=\"outputs\")\n\n        reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n\n        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n        loss = tf.add_n([reconstruction_loss] + reg_losses)\n\n        optimizer = tf.train.AdamOptimizer(learning_rate)\n        training_op = optimizer.minimize(loss)\n\n        init = tf.global_variables_initializer()\n\n    with tf.Session(graph=graph) as sess:\n        init.run()\n        for epoch in range(n_epochs):\n            n_batches = len(X_train) // batch_size\n            for iteration in range(n_batches):\n                print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n                sys.stdout.flush()\n                indices = rnd.permutation(len(X_train))[:batch_size]\n                X_batch = X_train[indices]\n                sess.run(training_op, feed_dict={X: X_batch})\n            loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n            print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)\n        params = dict([(var.name, var.eval()) for var in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)])\n        hidden_val = hidden.eval(feed_dict={X: X_train})\n        return hidden_val, params[\"hidden/kernel:0\"], params[\"hidden/bias:0\"], params[\"outputs/kernel:0\"], params[\"outputs/bias:0\"]", 
            "cell_type": "code", 
            "execution_count": 19, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "Now let's train two Autoencoders. The first one is trained on the training data, and the second is trained on the previous Autoencoder's hidden layer output:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "hidden_output, W1, b1, W4, b4 = train_autoencoder(mnist.train.images, n_neurons=300, n_epochs=4, batch_size=150,\n                                                  output_activation=None)\n_, W2, b2, W3, b3 = train_autoencoder(hidden_output, n_neurons=150, n_epochs=4, batch_size=150)", 
            "cell_type": "code", 
            "execution_count": 20, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 Train MSE: 0.0185175\n1 Train MSE: 0.0186825\n2 Train MSE: 0.0184675\n3 Train MSE: 0.0192315\n0 Train MSE: 0.00423609\n19% Train MSE: 0.00483262\n2 Train MSE: 0.00466869\n3 Train MSE: 0.00440386\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "Finally, we can create a Stacked Autoencoder by simply reusing the weights and biases from the Autoencoders we just trained:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "reset_graph()\n\nn_inputs = 28*28\n\nX = tf.placeholder(tf.float32, shape=[None, n_inputs])\nhidden1 = tf.nn.elu(tf.matmul(X, W1) + b1)\nhidden2 = tf.nn.elu(tf.matmul(hidden1, W2) + b2)\nhidden3 = tf.nn.elu(tf.matmul(hidden2, W3) + b3)\noutputs = tf.matmul(hidden3, W4) + b4", 
            "cell_type": "code", 
            "execution_count": 21, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "show_reconstructed_digits(X, outputs)", 
            "cell_type": "code", 
            "execution_count": 22, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7fe0f46b5790>"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "## Training one Autoencoder at a time in a single graph", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Another approach is to use a single graph. To do this, we create the graph for the full Stacked Autoencoder, but then we also add operations to train each Autoencoder independently: phase 1 trains the bottom and top layer (ie. the first Autoencoder) and phase 2 trains the two middle layers (ie. the second Autoencoder).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "reset_graph()\n\nn_inputs = 28 * 28\nn_hidden1 = 300\nn_hidden2 = 150  # codings\nn_hidden3 = n_hidden1\nn_outputs = n_inputs\n\nlearning_rate = 0.01\nl2_reg = 0.0001\n\nactivation = tf.nn.elu\nregularizer = tf.contrib.layers.l2_regularizer(l2_reg)\ninitializer = tf.contrib.layers.variance_scaling_initializer()\n\nX = tf.placeholder(tf.float32, shape=[None, n_inputs])\n\nweights1_init = initializer([n_inputs, n_hidden1])\nweights2_init = initializer([n_hidden1, n_hidden2])\nweights3_init = initializer([n_hidden2, n_hidden3])\nweights4_init = initializer([n_hidden3, n_outputs])\n\nweights1 = tf.Variable(weights1_init, dtype=tf.float32, name=\"weights1\")\nweights2 = tf.Variable(weights2_init, dtype=tf.float32, name=\"weights2\")\nweights3 = tf.Variable(weights3_init, dtype=tf.float32, name=\"weights3\")\nweights4 = tf.Variable(weights4_init, dtype=tf.float32, name=\"weights4\")\n\nbiases1 = tf.Variable(tf.zeros(n_hidden1), name=\"biases1\")\nbiases2 = tf.Variable(tf.zeros(n_hidden2), name=\"biases2\")\nbiases3 = tf.Variable(tf.zeros(n_hidden3), name=\"biases3\")\nbiases4 = tf.Variable(tf.zeros(n_outputs), name=\"biases4\")\n\nhidden1 = activation(tf.matmul(X, weights1) + biases1)\nhidden2 = activation(tf.matmul(hidden1, weights2) + biases2)\nhidden3 = activation(tf.matmul(hidden2, weights3) + biases3)\noutputs = tf.matmul(hidden3, weights4) + biases4\n\nreconstruction_loss = tf.reduce_mean(tf.square(outputs - X))", 
            "cell_type": "code", 
            "execution_count": 23, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "optimizer = tf.train.AdamOptimizer(learning_rate)\n\nwith tf.name_scope(\"phase1\"):\n    phase1_outputs = tf.matmul(hidden1, weights4) + biases4  # bypass hidden2 and hidden3\n    phase1_reconstruction_loss = tf.reduce_mean(tf.square(phase1_outputs - X))\n    phase1_reg_loss = regularizer(weights1) + regularizer(weights4)\n    phase1_loss = phase1_reconstruction_loss + phase1_reg_loss\n    phase1_training_op = optimizer.minimize(phase1_loss)\n\nwith tf.name_scope(\"phase2\"):\n    phase2_reconstruction_loss = tf.reduce_mean(tf.square(hidden3 - hidden1))\n    phase2_reg_loss = regularizer(weights2) + regularizer(weights3)\n    phase2_loss = phase2_reconstruction_loss + phase2_reg_loss\n    train_vars = [weights2, biases2, weights3, biases3]\n    phase2_training_op = optimizer.minimize(phase2_loss, var_list=train_vars) # freeze hidden1", 
            "cell_type": "code", 
            "execution_count": 24, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "init = tf.global_variables_initializer()\nsaver = tf.train.Saver()", 
            "cell_type": "code", 
            "execution_count": 25, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "training_ops = [phase1_training_op, phase2_training_op]\nreconstruction_losses = [phase1_reconstruction_loss, phase2_reconstruction_loss]\nn_epochs = [4, 4]\nbatch_sizes = [150, 150]\n\nwith tf.Session() as sess:\n    init.run()\n    for phase in range(2):\n        print(\"Training phase #{}\".format(phase + 1))\n        for epoch in range(n_epochs[phase]):\n            n_batches = mnist.train.num_examples // batch_sizes[phase]\n            for iteration in range(n_batches):\n                print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n                sys.stdout.flush()\n                X_batch, y_batch = mnist.train.next_batch(batch_sizes[phase])\n                sess.run(training_ops[phase], feed_dict={X: X_batch})\n            loss_train = reconstruction_losses[phase].eval(feed_dict={X: X_batch})\n            print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)\n            saver.save(sess, \"./my_model_one_at_a_time.ckpt\")\n    loss_test = reconstruction_loss.eval(feed_dict={X: mnist.test.images})\n    print(\"Test MSE:\", loss_test)", 
            "cell_type": "code", 
            "execution_count": 26, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Training phase #1\n0 Train MSE: 0.0074068\n1 Train MSE: 0.00782866\n2 Train MSE: 0.00772802\n3 Train MSE: 0.00740893\nTraining phase #2\n0 Train MSE: 0.279671\n1 Train MSE: 0.00553525\n2 Train MSE: 0.00291541\n3 Train MSE: 0.00238866\nTest MSE: 0.00976381\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "## Cache the frozen layer outputs", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "training_ops = [phase1_training_op, phase2_training_op]\nreconstruction_losses = [phase1_reconstruction_loss, phase2_reconstruction_loss]\nn_epochs = [4, 4]\nbatch_sizes = [150, 150]\n\nwith tf.Session() as sess:\n    init.run()\n    for phase in range(2):\n        print(\"Training phase #{}\".format(phase + 1))\n        if phase == 1:\n            hidden1_cache = hidden1.eval(feed_dict={X: mnist.train.images})\n        for epoch in range(n_epochs[phase]):\n            n_batches = mnist.train.num_examples // batch_sizes[phase]\n            for iteration in range(n_batches):\n                print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n                sys.stdout.flush()\n                if phase == 1:\n                    indices = rnd.permutation(mnist.train.num_examples)\n                    hidden1_batch = hidden1_cache[indices[:batch_sizes[phase]]]\n                    feed_dict = {hidden1: hidden1_batch}\n                    sess.run(training_ops[phase], feed_dict=feed_dict)\n                else:\n                    X_batch, y_batch = mnist.train.next_batch(batch_sizes[phase])\n                    feed_dict = {X: X_batch}\n                    sess.run(training_ops[phase], feed_dict=feed_dict)\n            loss_train = reconstruction_losses[phase].eval(feed_dict=feed_dict)\n            print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)\n            saver.save(sess, \"./my_model_cache_frozen.ckpt\")\n    loss_test = reconstruction_loss.eval(feed_dict={X: mnist.test.images})\n    print(\"Test MSE:\", loss_test)", 
            "cell_type": "code", 
            "execution_count": 27, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Training phase #1\n0 Train MSE: 0.00753817\n1 Train MSE: 0.00775457\n2 Train MSE: 0.00734359\n3 Train MSE: 0.00783768\nTraining phase #2\n0 Train MSE: 0.229686\n1 Train MSE: 0.00474355\n2 Train MSE: 0.00255261\n3 Train MSE: 0.00206523\nTest MSE: 0.00978721\n"
                }
            ], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "## Visualizing the Reconstructions", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "n_test_digits = 2\nX_test = mnist.test.images[:n_test_digits]\n\nwith tf.Session() as sess:\n    saver.restore(sess, \"./my_model_one_at_a_time.ckpt\") # not shown in the book\n    outputs_val = outputs.eval(feed_dict={X: X_test})\n\ndef plot_image(image, shape=[28, 28]):\n    plt.imshow(image.reshape(shape), cmap=\"Greys\", interpolation=\"nearest\")\n    plt.axis(\"off\")\n\nfor digit_index in range(n_test_digits):\n    plt.subplot(n_test_digits, 2, digit_index * 2 + 1)\n    plot_image(X_test[digit_index])\n    plt.subplot(n_test_digits, 2, digit_index * 2 + 2)\n    plot_image(outputs_val[digit_index])", 
            "cell_type": "code", 
            "execution_count": 28, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "INFO:tensorflow:Restoring parameters from ./my_model_one_at_a_time.ckpt\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7fe188326ed0>"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "## Visualizing the extracted features", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "with tf.Session() as sess:\n    saver.restore(sess, \"./my_model_one_at_a_time.ckpt\") # not shown in the book\n    weights1_val = weights1.eval()\n\nfor i in range(5):\n    plt.subplot(1, 5, i + 1)\n    plot_image(weights1_val.T[i])\n\n#save_fig(\"extracted_features_plot\") # not shown\nplt.show()                          # not shown", 
            "cell_type": "code", 
            "execution_count": 29, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "INFO:tensorflow:Restoring parameters from ./my_model_one_at_a_time.ckpt\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7fe2ff8e5850>"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# Unsupervised pretraining", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Let's create a small neural network for MNIST classification:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "reset_graph()\n\nn_inputs = 28 * 28\nn_hidden1 = 300\nn_hidden2 = 150\nn_outputs = 10\n\nlearning_rate = 0.01\nl2_reg = 0.0005\n\nactivation = tf.nn.elu\nregularizer = tf.contrib.layers.l2_regularizer(l2_reg)\ninitializer = tf.contrib.layers.variance_scaling_initializer()\n\nX = tf.placeholder(tf.float32, shape=[None, n_inputs])\ny = tf.placeholder(tf.int32, shape=[None])\n\nweights1_init = initializer([n_inputs, n_hidden1])\nweights2_init = initializer([n_hidden1, n_hidden2])\nweights3_init = initializer([n_hidden2, n_outputs])\n\nweights1 = tf.Variable(weights1_init, dtype=tf.float32, name=\"weights1\")\nweights2 = tf.Variable(weights2_init, dtype=tf.float32, name=\"weights2\")\nweights3 = tf.Variable(weights3_init, dtype=tf.float32, name=\"weights3\")\n\nbiases1 = tf.Variable(tf.zeros(n_hidden1), name=\"biases1\")\nbiases2 = tf.Variable(tf.zeros(n_hidden2), name=\"biases2\")\nbiases3 = tf.Variable(tf.zeros(n_outputs), name=\"biases3\")\n\nhidden1 = activation(tf.matmul(X, weights1) + biases1)\nhidden2 = activation(tf.matmul(hidden1, weights2) + biases2)\nlogits = tf.matmul(hidden2, weights3) + biases3\n\ncross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\nreg_loss = regularizer(weights1) + regularizer(weights2) + regularizer(weights3)\nloss = cross_entropy + reg_loss\noptimizer = tf.train.AdamOptimizer(learning_rate)\ntraining_op = optimizer.minimize(loss)\n\ncorrect = tf.nn.in_top_k(logits, y, 1)\naccuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n\ninit = tf.global_variables_initializer()\npretrain_saver = tf.train.Saver([weights1, weights2, biases1, biases2])\nsaver = tf.train.Saver()", 
            "cell_type": "code", 
            "execution_count": 30, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "Regular training (without pretraining):", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "n_epochs = 4\nbatch_size = 150\nn_labeled_instances = 20000\n\nwith tf.Session() as sess:\n    init.run()\n    for epoch in range(n_epochs):\n        n_batches = n_labeled_instances // batch_size\n        for iteration in range(n_batches):\n            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n            sys.stdout.flush()\n            indices = rnd.permutation(n_labeled_instances)[:batch_size]\n            X_batch, y_batch = mnist.train.images[indices], mnist.train.labels[indices]\n            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n        accuracy_val = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n        print(\"\\r{}\".format(epoch), \"Train accuracy:\", accuracy_val, end=\" \")\n        saver.save(sess, \"./my_model_supervised.ckpt\")\n        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n        print(\"Test accuracy:\", accuracy_val)", 
            "cell_type": "code", 
            "execution_count": 31, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 Train accuracy: 0.973333 Test accuracy: 0.9334\n1 Train accuracy: 0.98 Test accuracy: 0.936\n2 Train accuracy: 0.973333 Test accuracy: 0.9382\n3 Train accuracy: 0.986667 Test accuracy: 0.9492\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "Now reusing the first two layers of the autoencoder we pretrained:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "n_epochs = 4\nbatch_size = 150\nn_labeled_instances = 20000\n\n#training_op = optimizer.minimize(loss, var_list=[weights3, biases3])  # Freeze layers 1 and 2 (optional)\n\nwith tf.Session() as sess:\n    init.run()\n    pretrain_saver.restore(sess, \"./my_model_cache_frozen.ckpt\")\n    for epoch in range(n_epochs):\n        n_batches = n_labeled_instances // batch_size\n        for iteration in range(n_batches):\n            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n            sys.stdout.flush()\n            indices = rnd.permutation(n_labeled_instances)[:batch_size]\n            X_batch, y_batch = mnist.train.images[indices], mnist.train.labels[indices]\n            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n        accuracy_val = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n        print(\"\\r{}\".format(epoch), \"Train accuracy:\", accuracy_val, end=\"\\t\")\n        saver.save(sess, \"./my_model_supervised_pretrained.ckpt\")\n        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n        print(\"Test accuracy:\", accuracy_val)", 
            "cell_type": "code", 
            "execution_count": 32, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "INFO:tensorflow:Restoring parameters from ./my_model_cache_frozen.ckpt\n0 Train accuracy: 0.966667\tTest accuracy: 0.9261\n1 Train accuracy: 0.966667\tTest accuracy: 0.9366\n2 Train accuracy: 0.986667\tTest accuracy: 0.9367\n3 Train accuracy: 0.98\tTest accuracy: 0.9491\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# Stacked denoising Autoencoder", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Note: the book uses `tf.contrib.layers.dropout()` rather than `tf.layers.dropout()` (which did not exist when this chapter was written). It is now preferable to use `tf.layers.dropout()`, because anything in the contrib module may change or be deleted without notice. The `tf.layers.dropout()` function is almost identical to the `tf.contrib.layers.dropout()` function, except for a few minor differences. Most importantly:\n* you must specify the dropout rate (`rate`) rather than the keep probability (`keep_prob`), where `rate` is simply equal to `1 - keep_prob`,\n* the `is_training` parameter is renamed to `training`.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Using Gaussian noise:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "reset_graph()\n\nn_inputs = 28 * 28\nn_hidden1 = 300\nn_hidden2 = 150  # codings\nn_hidden3 = n_hidden1\nn_outputs = n_inputs\n\nlearning_rate = 0.01", 
            "cell_type": "code", 
            "execution_count": 33, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "noise_level = 1.0\n\nX = tf.placeholder(tf.float32, shape=[None, n_inputs])\nX_noisy = X + noise_level * tf.random_normal(tf.shape(X))\n\nhidden1 = tf.layers.dense(X_noisy, n_hidden1, activation=tf.nn.relu,\n                          name=\"hidden1\")\nhidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, # not shown in the book\n                          name=\"hidden2\")                            # not shown\nhidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, # not shown\n                          name=\"hidden3\")                            # not shown\noutputs = tf.layers.dense(hidden3, n_outputs, name=\"outputs\")        # not shown\n\nreconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) # MSE", 
            "cell_type": "code", 
            "execution_count": 34, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "optimizer = tf.train.AdamOptimizer(learning_rate)\ntraining_op = optimizer.minimize(reconstruction_loss)\n    \ninit = tf.global_variables_initializer()\nsaver = tf.train.Saver()", 
            "cell_type": "code", 
            "execution_count": 35, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "n_epochs = 10\nbatch_size = 150\n\nwith tf.Session() as sess:\n    init.run()\n    for epoch in range(n_epochs):\n        n_batches = mnist.train.num_examples // batch_size\n        for iteration in range(n_batches):\n            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n            sys.stdout.flush()\n            X_batch, y_batch = mnist.train.next_batch(batch_size)\n            sess.run(training_op, feed_dict={X: X_batch})\n        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n        print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)\n        saver.save(sess, \"./my_model_stacked_denoising_gaussian.ckpt\")", 
            "cell_type": "code", 
            "execution_count": 36, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 Train MSE: 0.0440489\n1 Train MSE: 0.0432517\n2 Train MSE: 0.042057\n3 Train MSE: 0.0409477\n4 Train MSE: 0.0402107\n5 Train MSE: 0.0388787\n6 Train MSE: 0.0391096\n7 Train MSE: 0.0421885\n8 Train MSE: 0.0398648\n9 Train MSE: 0.0408181\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "Using dropout:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "reset_graph()\n\nn_inputs = 28 * 28\nn_hidden1 = 300\nn_hidden2 = 150  # codings\nn_hidden3 = n_hidden1\nn_outputs = n_inputs\n\nlearning_rate = 0.01", 
            "cell_type": "code", 
            "execution_count": 37, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "dropout_rate = 0.3\n\ntraining = tf.placeholder_with_default(False, shape=(), name='training')\n\nX = tf.placeholder(tf.float32, shape=[None, n_inputs])\nX_drop = tf.layers.dropout(X, dropout_rate, training=training)\n\nhidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu,\n                          name=\"hidden1\")\nhidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, # not shown in the book\n                          name=\"hidden2\")                            # not shown\nhidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, # not shown\n                          name=\"hidden3\")                            # not shown\noutputs = tf.layers.dense(hidden3, n_outputs, name=\"outputs\")        # not shown\n\nreconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) # MSE", 
            "cell_type": "code", 
            "execution_count": 38, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "optimizer = tf.train.AdamOptimizer(learning_rate)\ntraining_op = optimizer.minimize(reconstruction_loss)\n    \ninit = tf.global_variables_initializer()\nsaver = tf.train.Saver()", 
            "cell_type": "code", 
            "execution_count": 39, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "n_epochs = 10\nbatch_size = 150\n\nwith tf.Session() as sess:\n    init.run()\n    for epoch in range(n_epochs):\n        n_batches = mnist.train.num_examples // batch_size\n        for iteration in range(n_batches):\n            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n            sys.stdout.flush()\n            X_batch, y_batch = mnist.train.next_batch(batch_size)\n            sess.run(training_op, feed_dict={X: X_batch, training: True})\n        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n        print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)\n        saver.save(sess, \"./my_model_stacked_denoising_dropout.ckpt\")", 
            "cell_type": "code", 
            "execution_count": 40, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 Train MSE: 0.0296476\n1 Train MSE: 0.0275545\n2 Train MSE: 0.0250731\n3 Train MSE: 0.0254317\n4 Train MSE: 0.0249076\n5 Train MSE: 0.0250501\n6 Train MSE: 0.024483\n7 Train MSE: 0.0251505\n8 Train MSE: 0.0243836\n9 Train MSE: 0.0242349\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "show_reconstructed_digits(X, outputs, \"./my_model_stacked_denoising_dropout.ckpt\")", 
            "cell_type": "code", 
            "execution_count": 41, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "INFO:tensorflow:Restoring parameters from ./my_model_stacked_denoising_dropout.ckpt\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7fe1642eec50>"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# Sparse Autoencoder", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "p = 0.1\nq = np.linspace(0.001, 0.999, 500)\nkl_div = p * np.log(p / q) + (1 - p) * np.log((1 - p) / (1 - q))\nmse = (p - q)**2\nplt.plot([p, p], [0, 0.3], \"k:\")\nplt.text(0.05, 0.32, \"Target\\nsparsity\", fontsize=14)\nplt.plot(q, kl_div, \"b-\", label=\"KL divergence\")\nplt.plot(q, mse, \"r--\", label=\"MSE\")\nplt.legend(loc=\"upper left\")\nplt.xlabel(\"Actual sparsity\")\nplt.ylabel(\"Cost\", rotation=0)\nplt.axis([0, 1, 0, 0.95])\n#save_fig(\"sparsity_loss_plot\")", 
            "cell_type": "code", 
            "execution_count": 42, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[0, 1, 0, 0.95]"
                    }, 
                    "execution_count": 42, 
                    "metadata": {}
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7fe070150bd0>"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "reset_graph()\n\nn_inputs = 28 * 28\nn_hidden1 = 1000  # sparse codings\nn_outputs = n_inputs", 
            "cell_type": "code", 
            "execution_count": 43, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "def kl_divergence(p, q):\n    # Kullback Leibler divergence\n    return p * tf.log(p / q) + (1 - p) * tf.log((1 - p) / (1 - q))\n\nlearning_rate = 0.01\nsparsity_target = 0.1\nsparsity_weight = 0.2\n\nX = tf.placeholder(tf.float32, shape=[None, n_inputs])            # not shown in the book\n\nhidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.sigmoid) # not shown\noutputs = tf.layers.dense(hidden1, n_outputs)                     # not shown\n\nhidden1_mean = tf.reduce_mean(hidden1, axis=0) # batch mean\nsparsity_loss = tf.reduce_sum(kl_divergence(sparsity_target, hidden1_mean))\nreconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) # MSE\nloss = reconstruction_loss + sparsity_weight * sparsity_loss\n\noptimizer = tf.train.AdamOptimizer(learning_rate)\ntraining_op = optimizer.minimize(loss)", 
            "cell_type": "code", 
            "execution_count": 44, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "init = tf.global_variables_initializer()\nsaver = tf.train.Saver()", 
            "cell_type": "code", 
            "execution_count": 45, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "n_epochs = 100\nbatch_size = 1000\n\nwith tf.Session() as sess:\n    init.run()\n    for epoch in range(n_epochs):\n        n_batches = mnist.train.num_examples // batch_size\n        for iteration in range(n_batches):\n            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n            sys.stdout.flush()\n            X_batch, y_batch = mnist.train.next_batch(batch_size)\n            sess.run(training_op, feed_dict={X: X_batch})\n        reconstruction_loss_val, sparsity_loss_val, loss_val = sess.run([reconstruction_loss, sparsity_loss, loss], feed_dict={X: X_batch})\n        print(\"\\r{}\".format(epoch), \"Train MSE:\", reconstruction_loss_val, \"\\tSparsity loss:\", sparsity_loss_val, \"\\tTotal loss:\", loss_val)\n        saver.save(sess, \"./my_model_sparse.ckpt\")", 
            "cell_type": "code", 
            "execution_count": 46, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 Train MSE: 0.134832 \tSparsity loss: 0.421739 \tTotal loss: 0.21918\n1 Train MSE: 0.0587859 \tSparsity loss: 0.0108979 \tTotal loss: 0.0609655\n2 Train MSE: 0.053738 \tSparsity loss: 0.0201038 \tTotal loss: 0.0577588\n3 Train MSE: 0.0476169 \tSparsity loss: 0.0399679 \tTotal loss: 0.0556105\n4 Train MSE: 0.0447499 \tSparsity loss: 0.0116199 \tTotal loss: 0.0470739\n5 Train MSE: 0.0403685 \tSparsity loss: 0.0930409 \tTotal loss: 0.0589767\n6 Train MSE: 0.0388338 \tSparsity loss: 0.0462908 \tTotal loss: 0.048092\n7 Train MSE: 0.0378196 \tSparsity loss: 0.0758871 \tTotal loss: 0.052997\n8 Train MSE: 0.0332092 \tSparsity loss: 0.0200693 \tTotal loss: 0.037223\n9 Train MSE: 0.0314318 \tSparsity loss: 0.0965061 \tTotal loss: 0.050733\n10 Train MSE: 0.0273777 \tSparsity loss: 0.0670885 \tTotal loss: 0.0407954\n11 Train MSE: 0.0246779 \tSparsity loss: 0.0900828 \tTotal loss: 0.0426945\n12 Train MSE: 0.0233311 \tSparsity loss: 0.0577432 \tTotal loss: 0.0348797\n13 Train MSE: 0.0228954 \tSparsity loss: 0.0623308 \tTotal loss: 0.0353615\n14 Train MSE: 0.0210913 \tSparsity loss: 0.0258186 \tTotal loss: 0.026255\n15 Train MSE: 0.0220006 \tSparsity loss: 0.483207 \tTotal loss: 0.118642\n16 Train MSE: 0.0190526 \tSparsity loss: 0.0361403 \tTotal loss: 0.0262806\n17 Train MSE: 0.0188885 \tSparsity loss: 0.132695 \tTotal loss: 0.0454275\n18 Train MSE: 0.0174156 \tSparsity loss: 0.0403093 \tTotal loss: 0.0254774\n19 Train MSE: 0.0178612 \tSparsity loss: 0.110486 \tTotal loss: 0.0399584\n20 Train MSE: 0.0168293 \tSparsity loss: 0.0291402 \tTotal loss: 0.0226573\n21 Train MSE: 0.0183871 \tSparsity loss: 0.364209 \tTotal loss: 0.0912289\n22 Train MSE: 0.0161226 \tSparsity loss: 0.0556278 \tTotal loss: 0.0272482\n23 Train MSE: 0.0158919 \tSparsity loss: 0.0792573 \tTotal loss: 0.0317434\n24 Train MSE: 0.0157006 \tSparsity loss: 0.149254 \tTotal loss: 0.0455514\n25 Train MSE: 0.0145307 \tSparsity loss: 0.136184 \tTotal loss: 0.0417676\n26 Train MSE: 0.0144209 \tSparsity loss: 0.110554 \tTotal loss: 0.0365316\n27 Train MSE: 0.0138508 \tSparsity loss: 0.0744676 \tTotal loss: 0.0287443\n28 Train MSE: 0.0139305 \tSparsity loss: 0.158476 \tTotal loss: 0.0456257\n29 Train MSE: 0.0133762 \tSparsity loss: 0.143838 \tTotal loss: 0.0421438\n30 Train MSE: 0.0137258 \tSparsity loss: 0.185643 \tTotal loss: 0.0508544\n31 Train MSE: 0.0139518 \tSparsity loss: 0.0635133 \tTotal loss: 0.0266544\n32 Train MSE: 0.013692 \tSparsity loss: 0.0577956 \tTotal loss: 0.0252512\n33 Train MSE: 0.0134704 \tSparsity loss: 0.104171 \tTotal loss: 0.0343045\n34 Train MSE: 0.0124406 \tSparsity loss: 0.136569 \tTotal loss: 0.0397544\n35 Train MSE: 0.0126563 \tSparsity loss: 0.162903 \tTotal loss: 0.0452369\n36 Train MSE: 0.0128764 \tSparsity loss: 0.0948648 \tTotal loss: 0.0318493\n37 Train MSE: 0.0123458 \tSparsity loss: 0.108087 \tTotal loss: 0.0339632\n38 Train MSE: 0.0121672 \tSparsity loss: 0.20089 \tTotal loss: 0.0523451\n39 Train MSE: 0.0122532 \tSparsity loss: 0.149409 \tTotal loss: 0.0421351\n40 Train MSE: 0.0125975 \tSparsity loss: 0.230649 \tTotal loss: 0.0587274\n41 Train MSE: 0.0124657 \tSparsity loss: 0.100664 \tTotal loss: 0.0325984\n42 Train MSE: 0.0116947 \tSparsity loss: 0.101108 \tTotal loss: 0.0319164\n43 Train MSE: 0.0122123 \tSparsity loss: 0.125789 \tTotal loss: 0.0373701\n44 Train MSE: 0.0117173 \tSparsity loss: 0.110301 \tTotal loss: 0.0337774\n45 Train MSE: 0.0116897 \tSparsity loss: 0.165081 \tTotal loss: 0.0447058\n46 Train MSE: 0.011611 \tSparsity loss: 0.130426 \tTotal loss: 0.0376962\n47 Train MSE: 0.0117358 \tSparsity loss: 0.163508 \tTotal loss: 0.0444374\n48 Train MSE: 0.0116507 \tSparsity loss: 0.459586 \tTotal loss: 0.103568\n49 Train MSE: 0.0116655 \tSparsity loss: 0.188114 \tTotal loss: 0.0492883\n50 Train MSE: 0.0114275 \tSparsity loss: 0.19221 \tTotal loss: 0.0498695\n51 Train MSE: 0.0113954 \tSparsity loss: 0.266457 \tTotal loss: 0.0646867\n52 Train MSE: 0.0119332 \tSparsity loss: 0.379985 \tTotal loss: 0.0879303\n53 Train MSE: 0.0113018 \tSparsity loss: 0.129771 \tTotal loss: 0.037256\n54 Train MSE: 0.0153057 \tSparsity loss: 0.434827 \tTotal loss: 0.102271\n55 Train MSE: 0.0134004 \tSparsity loss: 0.0833025 \tTotal loss: 0.0300609\n56 Train MSE: 0.0123188 \tSparsity loss: 0.297605 \tTotal loss: 0.0718399\n57 Train MSE: 0.0122943 \tSparsity loss: 0.247148 \tTotal loss: 0.061724\n58 Train MSE: 0.0239939 \tSparsity loss: 0.215717 \tTotal loss: 0.0671373\n59 Train MSE: 0.013596 \tSparsity loss: 0.203553 \tTotal loss: 0.0543065\n60 Train MSE: 0.0179108 \tSparsity loss: 0.180449 \tTotal loss: 0.0540006\n61 Train MSE: 0.0132258 \tSparsity loss: 0.231824 \tTotal loss: 0.0595906\n62 Train MSE: 0.0136533 \tSparsity loss: 0.498429 \tTotal loss: 0.113339\n63 Train MSE: 0.0143277 \tSparsity loss: 0.333901 \tTotal loss: 0.0811079\n64 Train MSE: 0.0119968 \tSparsity loss: 0.176848 \tTotal loss: 0.0473664\n65 Train MSE: 0.0156422 \tSparsity loss: 0.173917 \tTotal loss: 0.0504256\n66 Train MSE: 0.0150095 \tSparsity loss: 1.02187 \tTotal loss: 0.219383\n67 Train MSE: 0.036823 \tSparsity loss: 0.323619 \tTotal loss: 0.101547\n68 Train MSE: 0.0148193 \tSparsity loss: 0.230714 \tTotal loss: 0.060962\n69 Train MSE: 0.0126409 \tSparsity loss: 0.454552 \tTotal loss: 0.103551\n70 Train MSE: 0.045501 \tSparsity loss: 0.745102 \tTotal loss: 0.194521\n71 Train MSE: 0.0143786 \tSparsity loss: 0.229362 \tTotal loss: 0.060251\n72 Train MSE: 0.0151026 \tSparsity loss: 0.826014 \tTotal loss: 0.180306\n73 Train MSE: 0.0136122 \tSparsity loss: 0.316737 \tTotal loss: 0.0769596\n74 Train MSE: 0.0309757 \tSparsity loss: 0.289552 \tTotal loss: 0.0888861\n75 Train MSE: 0.0304744 \tSparsity loss: 0.489417 \tTotal loss: 0.128358\n76 Train MSE: 0.0204102 \tSparsity loss: 0.201982 \tTotal loss: 0.0608067\n77 Train MSE: 0.0211023 \tSparsity loss: 0.32347 \tTotal loss: 0.0857964\n78 Train MSE: 0.0178777 \tSparsity loss: 0.533425 \tTotal loss: 0.124563\n79 Train MSE: 0.018841 \tSparsity loss: 0.424661 \tTotal loss: 0.103773\n80 Train MSE: 0.0159234 \tSparsity loss: 0.115559 \tTotal loss: 0.0390352\n81 Train MSE: 0.0129649 \tSparsity loss: 0.912508 \tTotal loss: 0.195467\n82 Train MSE: 0.0162278 \tSparsity loss: 2.17347 \tTotal loss: 0.450922\n83 Train MSE: 0.0146708 \tSparsity loss: 0.681089 \tTotal loss: 0.150889\n84 Train MSE: 0.0150686 \tSparsity loss: 0.292309 \tTotal loss: 0.0735305\n85 Train MSE: 0.0250247 \tSparsity loss: 0.949989 \tTotal loss: 0.215023\n86 Train MSE: 0.0146914 \tSparsity loss: 0.685326 \tTotal loss: 0.151757\n87 Train MSE: 0.0122667 \tSparsity loss: 1.44823 \tTotal loss: 0.301912\n88 Train MSE: 0.0197259 \tSparsity loss: 0.861047 \tTotal loss: 0.191935\n89 Train MSE: 0.0331342 \tSparsity loss: 0.291833 \tTotal loss: 0.0915009\n90 Train MSE: 0.0295548 \tSparsity loss: 0.445159 \tTotal loss: 0.118587\n91 Train MSE: 0.0145762 \tSparsity loss: 0.0887034 \tTotal loss: 0.0323169\n92 Train MSE: 0.0147775 \tSparsity loss: 0.390856 \tTotal loss: 0.0929486\n93 Train MSE: 0.0166543 \tSparsity loss: 0.155326 \tTotal loss: 0.0477195\n94 Train MSE: 0.012198 \tSparsity loss: 0.12071 \tTotal loss: 0.03634\n95 Train MSE: 0.0141104 \tSparsity loss: 0.107212 \tTotal loss: 0.0355529\n96 Train MSE: 0.018834 \tSparsity loss: 0.230255 \tTotal loss: 0.0648851\n97 Train MSE: 0.0134663 \tSparsity loss: 0.102045 \tTotal loss: 0.0338754\n98 Train MSE: 0.013678 \tSparsity loss: 0.0839055 \tTotal loss: 0.0304591\n99 Train MSE: 0.0245401 \tSparsity loss: 0.335841 \tTotal loss: 0.0917084\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "show_reconstructed_digits(X, outputs, \"./my_model_sparse.ckpt\")", 
            "cell_type": "code", 
            "execution_count": 48, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "INFO:tensorflow:Restoring parameters from ./my_model_sparse.ckpt\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7fe06801d790>"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "Note that the coding layer must output values from 0 to 1, which is why we use the sigmoid activation function:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.sigmoid)", 
            "cell_type": "code", 
            "execution_count": 49, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "To speed up training, you can normalize the inputs between 0 and 1, and use the cross entropy instead of the MSE for the cost function:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "logits = tf.layers.dense(hidden1, n_outputs)\noutputs = tf.nn.sigmoid(logits)\n\nxentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=logits)\nreconstruction_loss = tf.reduce_mean(xentropy)", 
            "cell_type": "code", 
            "execution_count": 50, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# Variational Autoencoder", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "reset_graph()\n\nfrom functools import partial\n\nn_inputs = 28 * 28\nn_hidden1 = 500\nn_hidden2 = 500\nn_hidden3 = 20  # codings\nn_hidden4 = n_hidden2\nn_hidden5 = n_hidden1\nn_outputs = n_inputs\nlearning_rate = 0.001\n\ninitializer = tf.contrib.layers.variance_scaling_initializer()\n\nmy_dense_layer = partial(\n    tf.layers.dense,\n    activation=tf.nn.elu,\n    kernel_initializer=initializer)\n\nX = tf.placeholder(tf.float32, [None, n_inputs])\nhidden1 = my_dense_layer(X, n_hidden1)\nhidden2 = my_dense_layer(hidden1, n_hidden2)\nhidden3_mean = my_dense_layer(hidden2, n_hidden3, activation=None)\nhidden3_sigma = my_dense_layer(hidden2, n_hidden3, activation=None)\nnoise = tf.random_normal(tf.shape(hidden3_sigma), dtype=tf.float32)\nhidden3 = hidden3_mean + hidden3_sigma * noise\nhidden4 = my_dense_layer(hidden3, n_hidden4)\nhidden5 = my_dense_layer(hidden4, n_hidden5)\nlogits = my_dense_layer(hidden5, n_outputs, activation=None)\noutputs = tf.sigmoid(logits)\n\nxentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=logits)\nreconstruction_loss = tf.reduce_sum(xentropy)", 
            "cell_type": "code", 
            "execution_count": 19, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "eps = 1e-10 # smoothing term to avoid computing log(0) which is NaN\nlatent_loss = 0.5 * tf.reduce_sum(\n    tf.square(hidden3_sigma) + tf.square(hidden3_mean)\n    - 1 - tf.log(eps + tf.square(hidden3_sigma)))", 
            "cell_type": "code", 
            "execution_count": 20, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "loss = reconstruction_loss + latent_loss\n\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntraining_op = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\nsaver = tf.train.Saver()", 
            "cell_type": "code", 
            "execution_count": 21, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "n_epochs = 50\nbatch_size = 150\n\nwith tf.Session() as sess:\n    init.run()\n    for epoch in range(n_epochs):\n        n_batches = mnist.train.num_examples // batch_size\n        for iteration in range(n_batches):\n            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n            sys.stdout.flush()\n            X_batch, y_batch = mnist.train.next_batch(batch_size)\n            sess.run(training_op, feed_dict={X: X_batch})\n        loss_val, reconstruction_loss_val, latent_loss_val = sess.run([loss, reconstruction_loss, latent_loss], feed_dict={X: X_batch})\n        print(\"\\r{}\".format(epoch), \"Train total loss:\", loss_val, \"\\tReconstruction loss:\", reconstruction_loss_val, \"\\tLatent loss:\", latent_loss_val)\n        saver.save(sess, \"./my_model_variational.ckpt\")", 
            "cell_type": "code", 
            "execution_count": 22, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 Train total loss: 30338.9 \tReconstruction loss: 24411.3 \tLatent loss: 5927.66\n1 Train total loss: 29236.9 \tReconstruction loss: 24008.3 \tLatent loss: 5228.58\n58%"
                }, 
                {
                    "output_type": "error", 
                    "evalue": "", 
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-22-30ca4f18a5ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction_loss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_loss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\r{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Train total loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\tReconstruction loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction_loss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\tLatent loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_loss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v91/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v91/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v91/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v91/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v91/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ], 
                    "ename": "KeyboardInterrupt"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "reset_graph()\n\nfrom functools import partial\n\nn_inputs = 28 * 28\nn_hidden1 = 500\nn_hidden2 = 500\nn_hidden3 = 20  # codings\nn_hidden4 = n_hidden2\nn_hidden5 = n_hidden1\nn_outputs = n_inputs\nlearning_rate = 0.001\n\ninitializer = tf.contrib.layers.variance_scaling_initializer()\nmy_dense_layer = partial(\n    tf.layers.dense,\n    activation=tf.nn.elu,\n    kernel_initializer=initializer)\n\nX = tf.placeholder(tf.float32, [None, n_inputs])\nhidden1 = my_dense_layer(X, n_hidden1)\nhidden2 = my_dense_layer(hidden1, n_hidden2)\nhidden3_mean = my_dense_layer(hidden2, n_hidden3, activation=None)\nhidden3_gamma = my_dense_layer(hidden2, n_hidden3, activation=None)\nnoise = tf.random_normal(tf.shape(hidden3_gamma), dtype=tf.float32)\nhidden3 = hidden3_mean + tf.exp(0.5 * hidden3_gamma) * noise\nhidden4 = my_dense_layer(hidden3, n_hidden4)\nhidden5 = my_dense_layer(hidden4, n_hidden5)\nlogits = my_dense_layer(hidden5, n_outputs, activation=None)\noutputs = tf.sigmoid(logits)\n\nxentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=logits)\nreconstruction_loss = tf.reduce_sum(xentropy)\nlatent_loss = 0.5 * tf.reduce_sum(\n    tf.exp(hidden3_gamma) + tf.square(hidden3_mean) - 1 - hidden3_gamma)\nloss = reconstruction_loss + latent_loss\n\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntraining_op = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\nsaver = tf.train.Saver()", 
            "cell_type": "code", 
            "execution_count": 23, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "## Generate digits", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Let's train the model and generate a few random digits:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import numpy as np\n\nn_digits = 60\nn_epochs = 50\nbatch_size = 150\n\nwith tf.Session() as sess:\n    init.run()\n    for epoch in range(n_epochs):\n        n_batches = mnist.train.num_examples // batch_size\n        for iteration in range(n_batches):\n            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\") # not shown in the book\n            sys.stdout.flush()                                          # not shown\n            X_batch, y_batch = mnist.train.next_batch(batch_size)\n            sess.run(training_op, feed_dict={X: X_batch})\n        loss_val, reconstruction_loss_val, latent_loss_val = sess.run([loss, reconstruction_loss, latent_loss], feed_dict={X: X_batch}) # not shown\n        print(\"\\r{}\".format(epoch), \"Train total loss:\", loss_val, \"\\tReconstruction loss:\", reconstruction_loss_val, \"\\tLatent loss:\", latent_loss_val)  # not shown\n        saver.save(sess, \"./my_model_variational.ckpt\")  # not shown\n    \n    codings_rnd = np.random.normal(size=[n_digits, n_hidden3])\n    outputs_val = outputs.eval(feed_dict={hidden3: codings_rnd})", 
            "cell_type": "code", 
            "execution_count": 24, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 Train total loss: 18027.6 \tReconstruction loss: 14424.5 \tLatent loss: 3603.12\n1 Train total loss: 17476.5 \tReconstruction loss: 13789.8 \tLatent loss: 3686.71\n47%"
                }, 
                {
                    "output_type": "error", 
                    "evalue": "", 
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-24-219a985e910e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                          \u001b[0;31m# not shown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction_loss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_loss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# not shown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\r{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Train total loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\tReconstruction loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction_loss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\tLatent loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_loss_val\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# not shown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v91/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v91/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v91/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v91/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v91/notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ], 
                    "ename": "KeyboardInterrupt"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "plt.figure(figsize=(8,50)) # not shown in the book\nfor iteration in range(n_digits):\n    plt.subplot(n_digits, 10, iteration + 1)\n    plot_image(outputs_val[iteration])", 
            "cell_type": "code", 
            "execution_count": 25, 
            "outputs": [
                {
                    "output_type": "error", 
                    "evalue": "name 'outputs_val' is not defined", 
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-25-a9a3d330e158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_digits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_digits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplot_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;31mNameError\u001b[0m: name 'outputs_val' is not defined"
                    ], 
                    "ename": "NameError"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7f68b473ba90>"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "n_rows = 6\nn_cols = 10\nplot_multiple_images(outputs_val.reshape(-1, 28, 28), n_rows, n_cols)\n#save_fig(\"generated_digits_plot\")\nplt.show()", 
            "cell_type": "code", 
            "execution_count": 26, 
            "outputs": [
                {
                    "output_type": "error", 
                    "evalue": "name 'outputs_val' is not defined", 
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-26-e742b07aef35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_multiple_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#save_fig(\"generated_digits_plot\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mNameError\u001b[0m: name 'outputs_val' is not defined"
                    ], 
                    "ename": "NameError"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "Note that the latent loss is computed differently in this second variant:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "latent_loss = 0.5 * tf.reduce_sum(\n    tf.exp(hidden3_gamma) + tf.square(hidden3_mean) - 1 - hidden3_gamma)", 
            "cell_type": "code", 
            "execution_count": 59, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "## Encode & Decode", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Encode:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "batch_size = 150\n\nn_digits = 3\nX_test, y_test = mnist.test.next_batch(batch_size)\ncodings = hidden3\n\nwith tf.Session() as sess:\n    saver.restore(sess, \"./my_model_variational.ckpt\")\n    codings_val = codings.eval(feed_dict={X: X_test})", 
            "cell_type": "code", 
            "execution_count": 12, 
            "outputs": [
                {
                    "output_type": "error", 
                    "evalue": "name 'hidden3' is not defined", 
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-12-e83ffa2fda23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_digits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mNameError\u001b[0m: name 'hidden3' is not defined"
                    ], 
                    "ename": "NameError"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "Decode:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "with tf.Session() as sess:\n    saver.restore(sess, \"./my_model_variational.ckpt\")\n    outputs_val = outputs.eval(feed_dict={codings: codings_val})", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "Let's plot the reconstructions:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "fig = plt.figure(figsize=(8, 2.5 * n_digits))\nfor iteration in range(n_digits):\n    plt.subplot(n_digits, 2, 1 + 2 * iteration)\n    plot_image(X_test[iteration])\n    plt.subplot(n_digits, 2, 2 + 2 * iteration)\n    plot_image(outputs_val[iteration])", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "## Interpolate digits", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "n_iterations = 3\nn_digits = 6\ncodings_rnd = np.random.normal(size=[n_digits, n_hidden3])\n\nwith tf.Session() as sess:\n    saver.restore(sess, \"./my_model_variational.ckpt\")\n    target_codings = np.roll(codings_rnd, -1, axis=0)\n    for iteration in range(n_iterations + 1):\n        codings_interpolate = codings_rnd + (target_codings - codings_rnd) * iteration / n_iterations\n        outputs_val = outputs.eval(feed_dict={codings: codings_interpolate})\n        plt.figure(figsize=(11, 1.5*n_iterations))\n        for digit_index in range(n_digits):\n            plt.subplot(1, n_digits, digit_index + 1)\n            plot_image(outputs_val[digit_index])\n        plt.show()", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "# Exercise solutions", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "Coming soon...", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "toc": {
            "toc_window_display": false, 
            "number_sections": true, 
            "threshold": 6, 
            "navigate_menu": true, 
            "toc_section_display": "block", 
            "sideBar": true, 
            "toc_cell": false
        }, 
        "nav_menu": {
            "width": "453px", 
            "height": "381px"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.14", 
            "name": "python", 
            "pygments_lexer": "ipython2", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }
}